{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "from urllib.parse import unquote_plus\n",
    "import os \n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "\n",
    "import sys\n",
    "from pip._internal import main\n",
    "main(['install', '-I', '-q', 'boto3', '--target', '/tmp/', '--no-cache-dir', '--disable-pip-version-check'])\n",
    "sys.path.insert(0,'/tmp/')\n",
    "import boto3\n",
    "\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    sqs= boto3.client('sqs')\n",
    "    textract = boto3.client(\"textract\")\n",
    "\n",
    "    fileObj = s3.get_object(Bucket='annualreport21-22', Key='annual-report-2021-2022.pdf')\n",
    "    file_content = fileObj[\"Body\"].read()\n",
    "    pdf = PyPDF2.PdfFileReader(BytesIO(file_content))\n",
    "    print(len(pdf.pages))\n",
    "    sizePDF=len(file_content)\n",
    "    print(sizePDF)\n",
    "  #####################################Read CSV##############################################\n",
    "    x=[]\n",
    "    df = wr.s3.read_csv('s3://annualreport21-22/Queries.csv')\n",
    "    # print(df['Page '])\n",
    "\n",
    "    first_page=df.iloc[0,0]\n",
    "    last_page=df.iloc[-1,0]\n",
    "    print(first_page)\n",
    "    print(last_page)\n",
    "  ####################################Chunk File into Single Pages######################################################3  \n",
    "    pages=list(df.iloc[:,0].unique())\n",
    "    \n",
    "    for i in pages:\n",
    "        writer = PyPDF2.PdfFileWriter()\n",
    "        page = pdf.getPage(i-1)\n",
    "        writer.addPage(page)\n",
    "        filename='Page'+str(i)+'.pdf'\n",
    "        os.chdir('/tmp')\n",
    "        with open(filename, \"wb\") as x:\n",
    "            writer.write(x)\n",
    "        s3.upload_file(filename, 'splitfiles21-22', filename)\n",
    "        print(filename +\" uploaded\")\n",
    "        os.remove(filename)\n",
    "######################################Return analysis jobs for n pages#############################################################  \n",
    "    # answers list\n",
    "    answers=[]\n",
    "    \n",
    "    for i in pages:\n",
    "        filename='Page'+str(i)+'.pdf'\n",
    "        x=pd.DataFrame(df.loc[df['Page '] == i])\n",
    "        y=list(x['Query'])\n",
    "        queries=[]\n",
    "        for j in y:\n",
    "            queries.append({\"Text\":j})\n",
    "        # print(queries)\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        response = textract.start_document_analysis(\n",
    "                DocumentLocation={\n",
    "                    'S3Object': {\n",
    "                        'Bucket': 'splitfiles21-22',\n",
    "                        'Name': filename\n",
    "                    }\n",
    "                },\n",
    "                FeatureTypes=[\n",
    "                    # 'FORMS','TABLES',\n",
    "                    'QUERIES'],\n",
    "                QueriesConfig={\"Queries\": queries},\n",
    "                OutputConfig={\n",
    "                    'S3Bucket': 'textract-output-21-22'\n",
    "                    })\n",
    "        job_id=response[\"JobId\"]\n",
    "        \n",
    "        print(\"********Textract Response***********\")\n",
    "        print(response)\n",
    "        ##################################Get Output######################\n",
    "        time.sleep(30)\n",
    "        analysis_response = textract.get_document_analysis(JobId=job_id)\n",
    "        print(\"********Analysis Response***********\")\n",
    "        time.sleep(30)\n",
    "        print(analysis_response)\n",
    "        \n",
    "        for i in analysis_response['Blocks']:\n",
    "                if i['BlockType']=='QUERY_RESULT':\n",
    "                    print(i['Text'])\n",
    "                    answers.append(i['Text'])\n",
    "        \n",
    "        \n",
    "##################################Store Output Back to CSV#########################################\n",
    "\n",
    "    df[\"Answer\"]=answers\n",
    "    wr.s3.to_csv(df, 's3://processed-output-21-22/Query-Answers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
